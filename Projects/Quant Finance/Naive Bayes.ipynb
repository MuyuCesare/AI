{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## 读取行业数据\n",
    "industry_data = pd.read_csv('data_1.0\\\\INDUSTRY_GICS.csv', index_col=0, )\n",
    "industry_data.head()\n",
    "\n",
    "# 保存数据\n",
    "industry_data.to_csv('data_1.0\\\\labeled_industry.csv')\n",
    "\n",
    "##市值分组转数字标签\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# 读取市值数据\n",
    "cap = pd.read_csv(\n",
    "    'data_1.0\\\\MKT_CAP_ARD.csv',\n",
    "    index_col=0\n",
    ")\n",
    "cap.head()\n",
    "\n",
    "# 读取交易量数据，用于排除停牌股票，交易量为0则停牌\n",
    "volume = pd.read_csv(\n",
    "    'data_1.0\\\\VOLUME.csv',\n",
    "    index_col=0\n",
    ")\n",
    "volume.head()\n",
    "\n",
    "# 将市值对数化\n",
    "lcap = np.log(cap)\n",
    "lcap.tail()\n",
    "\n",
    "# 识别交易量为NAN值或0为股票停牌，设置对应时间股票市值数据为nan不参与后续分组，机器学习模型里面特征一般不允许是Nan\n",
    "lcap[((volume.isna())|(volume==0))] = np.nan\n",
    "# lcap.dropna(axis=0, inplace=True, how='all')\n",
    "\n",
    "# 保存2013年以后的数据\n",
    "lcap = lcap.loc['2013-01-04':]\n",
    "lcap.head()\n",
    "\n",
    "# 将股票按照市值分成5组，每组中股票数量相等\n",
    "numerical_labeled_lcap = lcap.apply(pd.qcut, axis=1, q=5, labels=False)\n",
    "numerical_labeled_lcap.tail()\n",
    "\n",
    "# 保存数据\n",
    "numerical_labeled_lcap.to_csv('data_1.0\\\\numerical_labeled_lcap.csv')\n",
    "\n",
    "##动量计算转数字标签\n",
    "# 读取收盘价数据\n",
    "close = pd.read_csv(\n",
    "    'data_1.0\\\\CLOSE.csv',\n",
    "    index_col=0\n",
    ")\n",
    "close.head()\n",
    "\n",
    "# 读取交易量数据\n",
    "volume = pd.read_csv(\n",
    "    'data_1.0\\\\VOLUME.csv',\n",
    "    index_col=0\n",
    ")\n",
    "close.tail()\n",
    "\n",
    "# 识别交易量为NAN值或0为股票停牌，设置对应时间股票市值数据为nan不参与后续分组        # 注意pandas需要升级版本，否则没有isna()函数；\n",
    "close[(volume.isna()) | (volume==0)] = np.nan\n",
    "\n",
    "# 计算5日动能\n",
    "# mom = close.pct_change(periods=5)\n",
    "# mom.tail()\n",
    "\n",
    "mom = close/close.shift(5)-1\n",
    "\n",
    "# 去除缺失值\n",
    "mom.dropna(axis=0,inplace=True, how='all')\n",
    "\n",
    "mom = mom.loc['2013-01-04':]\n",
    "mom.head(20)\n",
    "\n",
    "# 将股票按照动能分成5组，每组中股票数量相等, 按行去做；\n",
    "numerical_labeled_mom = mom.apply(pd.qcut, axis=1, q=5, labels=False)\n",
    "numerical_labeled_mom.tail()\n",
    "\n",
    "numerical_labeled_mom.to_csv('data_1.0\\\\numerical_labeled_mom.csv')\n",
    "\n",
    "##非停牌股票日收益率计算\n",
    "# 读取收盘价数据\n",
    "close = pd.read_csv(\n",
    "    'data_1.0\\\\CLOSE.csv',\n",
    "    index_col=0\n",
    ")\n",
    "close.head()\n",
    "\n",
    "# 读取交易量数据\n",
    "volume = pd.read_csv(\n",
    "    'data_1.0\\\\VOLUME.csv',\n",
    "    index_col=0\n",
    ")\n",
    "volume.tail()\n",
    "\n",
    "# 识别交易量为NAN值或0为股票停牌，设置对应时间股票市值数据为nan不参与后续分组\n",
    "close[(volume.isna()) | (volume==0)] = np.nan\n",
    "\n",
    "# 计算日收益率\n",
    "close.sort_index(inplace=True)\n",
    "pct_change = close.pct_change()\n",
    "pct_change.tail()\n",
    "\n",
    "# 取出2013年以后的数据\n",
    "pct_change = pct_change.loc['2013-01-04':]\n",
    "pct_change.head()\n",
    "\n",
    "# 保存数据\n",
    "pct_change.to_csv('data_1.0\\\\pct_change.csv')\n",
    "\n",
    "##非停牌股票日收益率转数字标签\n",
    "# 读取收盘价数据\n",
    "close = pd.read_csv(\n",
    "    'data_1.0\\\\CLOSE.csv',\n",
    "    index_col=0\n",
    ")\n",
    "close.head()\n",
    "\n",
    "# 读取交易量数据\n",
    "volume = pd.read_csv(\n",
    "    'data_1.0\\\\VOLUME.csv',\n",
    "    index_col=0\n",
    ")\n",
    "volume.tail()\n",
    "\n",
    "# # 识别交易量为NAN值或0为股票停牌，设置对应时间股票市值数据为nan不参与后续分组\n",
    "close[(volume.isna()) | (volume==0)] = np.nan\n",
    "\n",
    "# 计算日收益率\n",
    "close.sort_index(inplace=True)\n",
    "pct_change = close.pct_change()\n",
    "pct_change.tail()\n",
    "\n",
    "# 去除缺失值\n",
    "pct_change.dropna(axis=0,inplace=True, how='all')\n",
    "\n",
    "pct_change = pct_change.loc['2013-01-04':]\n",
    "pct_change.head()\n",
    "\n",
    "# 对于上涨的股票标记为1，下跌或涨幅为0的股票标记为0\n",
    "pct_change[pct_change > 0]=1\n",
    "pct_change[pct_change <= 0]=0\n",
    "pct_change.head()\n",
    "\n",
    "pct_change.to_csv('data_1.0\\\\labeled_pct_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据读取\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import warnings; warnings.simplefilter('ignore') #忽略可能会出现的警告信息，警告并不是错误，可以忽略；\n",
    "\n",
    "start_date = '2013-01-11'\n",
    "end_date='2017-01-01'\n",
    "\n",
    "# 读取收益率数据\n",
    "pct_change = pd.read_csv(\n",
    "    'data_1.0\\\\pct_change.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "pct_change.head()\n",
    "\n",
    "# 读取市值标签数据\n",
    "labeled_lcap = pd.read_csv(\n",
    "    'data_1.0\\\\numerical_labeled_lcap.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "labeled_lcap.head()\n",
    "\n",
    "# 读取动量标签数据\n",
    "labeled_mom = pd.read_csv(\n",
    "    'data_1.0\\\\numerical_labeled_mom.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "labeled_mom.head()\n",
    "\n",
    "# 读取行业标签数据\n",
    "labeled_industry = pd.read_csv(\n",
    "    'data_1.0\\\\labeled_industry.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "labeled_industry.head()\n",
    "\n",
    "# 读取成交量数据，用于制作交易日历；用于在循环的过程中，帮助我们控制具体的日期；usecols指定读取的列\n",
    "volume = pd.read_csv(\n",
    "    'data_1.0\\\\VOLUME.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    usecols=[0,]\n",
    ")\n",
    "volume.head()\n",
    "\n",
    "# 读取收益率标签数据\n",
    "labeled_pct_change = pd.read_csv(\n",
    "    'data_1.0\\\\labeled_pct_change.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "labeled_pct_change.head()\n",
    "\n",
    "# 取出回测范围内的交易日期，用于循环去控制日期；\n",
    "volume.sort_index(inplace=True)\n",
    "new_volume = volume.loc[start_date:end_date]\n",
    "trade_calendar = new_volume.index\n",
    "trade_calendar\n",
    "\n",
    "##策略核心\n",
    "# 创建空Series用于储存策略收益率\n",
    "strategy_return = pd.Series(index=trade_calendar)\n",
    "\n",
    "# 进行策略回测\n",
    "# i = 101\n",
    "for i in range(len(trade_calendar)-2):\n",
    "\n",
    "    # 获取训练对应x，y数据的时间和预测时x，y数据的时间\n",
    "    train_x_time = trade_calendar[i]\n",
    "    train_y_time = trade_calendar[i+1]\n",
    "    predict_x_time = trade_calendar[i+1]\n",
    "    predict_y_time = trade_calendar[i+2]\n",
    "\n",
    "    # 模型训练用数据读取\n",
    "    train_data = pd.DataFrame(\n",
    "        {\n",
    "            'labeled_industry': labeled_industry.loc[train_x_time], #.loc取出行后会返回一个列名为index的ndarray\n",
    "            'labeled_lcap': labeled_lcap.loc[train_x_time]+200, #要加200是因为伯努利模型要防止不同特征在dummy时取到相同取值\n",
    "            'labeled_mom': labeled_mom.loc[train_x_time]+300,\n",
    "\n",
    "            'labeled_pct_change':labeled_pct_change.loc[train_y_time]\n",
    "        }\n",
    "    )\n",
    "    train_data.dropna(axis=0, inplace=True, how='any')\n",
    "    #train_data\n",
    "\n",
    "    # 生成训练用哑变量矩阵\n",
    "    dummy_data1 = pd.get_dummies(train_data['labeled_industry'])\n",
    "    dummy_data2 = pd.get_dummies(train_data['labeled_lcap'])\n",
    "    dummy_data3 = pd.get_dummies(train_data['labeled_mom'])\n",
    "\n",
    "    # 合并哑变量矩阵train_x，将特征拼接起来\n",
    "    dummy_train_x = pd.concat([dummy_data1, dummy_data2, dummy_data3], axis=1)\n",
    "    #dummy_train_x.head()\n",
    "\n",
    "    # 模型预测用数据读取\n",
    "    predict_data = pd.DataFrame(\n",
    "        {\n",
    "            'labeled_industry': labeled_industry.loc[predict_x_time],\n",
    "            'labeled_lcap': labeled_lcap.loc[predict_x_time]+200,\n",
    "            'labeled_mom': labeled_mom.loc[predict_x_time]+300,\n",
    "\n",
    "            'pct_change': pct_change.loc[predict_y_time]\n",
    "        }\n",
    "    )\n",
    "    predict_data.dropna(axis=0, inplace=True, how='any')\n",
    "    #predict_data.head()\n",
    "    \n",
    "    #  生成预测用哑变量矩阵\n",
    "    dummy_predict_data1 = pd.get_dummies(predict_data['labeled_industry'])\n",
    "    dummy_predict_data2 = pd.get_dummies(predict_data['labeled_lcap'])\n",
    "    dummy_predict_data3 = pd.get_dummies(predict_data['labeled_mom'])\n",
    "    #dummy_predict_data3.head()\n",
    "    # 合并哑变量矩阵predict_x\n",
    "    dummy_predict_x = pd.concat([dummy_predict_data1, dummy_predict_data2, dummy_predict_data3], axis=1)\n",
    "    #dummy_predict_x.head()\n",
    "\n",
    "    # 由于训练和预测的特征数量可能不同，所以需要columns的并集对列标签进行调整。比如某行业的所有公司在某时刻都处于停牌，下一天有些公司复牌，则在该时刻训练集会少一个行业(被dropna)但测试集没有少，导致训练出问题\n",
    "    character_union = dummy_train_x.columns.union(dummy_predict_x.columns) #对训练集和测试集的列标签取并集\n",
    "    dummy_train_x = dummy_train_x.reindex(columns=character_union, fill_value=0) #.reindex能够将索引进行加减，注意不是重命名index或列名，而是参数index或columns指定的列表中同名的会保留，如果列表中有dataframe中没有的，则会新增该index或列，fill_value指定新增的填充值，不指定默认为NaN\n",
    "    dummy_predict_x = dummy_predict_x.reindex(columns=character_union, fill_value=0)\n",
    "    \n",
    "    # 训练模型\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(dummy_train_x.values, train_data['labeled_pct_change'].values) #.values是因为传入sklearn分类器的数据一般要求为ndarray\n",
    "    \n",
    "    # 进行预测并保存数据\n",
    "    prediction = clf.predict(dummy_predict_x.values)\n",
    "    predict_data['prediction'] = prediction\n",
    "    #predict_data\n",
    "\n",
    "# 方法一：\n",
    "    # 计算预测日策略收益率并保存到Series中\n",
    "    if predict_data['prediction'].sum() == 0: #防止出现整个策略期内都没有成交信号，prediction全为0，导致计算时分母为0的情况\n",
    "        strategy_return[predict_y_time] = 0\n",
    "    else:\n",
    "        strategy_return[predict_y_time] = np.average(predict_data['pct_change'], weights=predict_data['prediction']) #以持仓为权重的收益率的加权平均，等价于方法二的结果\n",
    "    # strategy_return.head()\n",
    "    ### 注意：此方法涉及股票是否停牌的未来数据，对于predict_y_time日停牌的股票，策略回测时选择不持仓\n",
    "\n",
    "# # 方法二：收益率*持仓/总共购买的股票数\n",
    "# strategy_return[predict_y_time] = np.sum(predict_data['pct_change'] * predict_data['prediction'])/np.sum(predict_data['prediction'])\n",
    "# strategy_return.head()\n",
    "# strategy_return[:5]\n",
    "\n",
    "##策略收益绘图\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn\n",
    "import tushare as ts\n",
    "\n",
    "benchmark = ts.get_k_data('399006','2013-01-01','2017-01-01')\n",
    "benchmark.index = pd.to_datetime(benchmark['date'])\n",
    "\n",
    "benchmark = (benchmark['close'].pct_change()+ 1).cumprod()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot((strategy_return+1).cumprod(), label='strategy_return')\n",
    "plt.plot(benchmark, label='benchmark')\n",
    "plt.yticks()\n",
    "plt.tit\n",
    "plt.xticks(rotation=45, )\n",
    "plt.legend()\n",
    "\n",
    "##没有考虑交易成本、没有剔除涨停股票"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
