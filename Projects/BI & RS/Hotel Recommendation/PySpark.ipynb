{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark 酒店推荐系统\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#from pyspark.ml.feature import NGram\n",
    "\n",
    "# 创建SparkSession，2.0版本之后只需要创建一个SparkSession即可\n",
    "spark=SparkSession.builder.appName('hotel_rec_app').getOrCreate()\n",
    "\n",
    "# 从CSV文件中读取\n",
    "df = spark.read.csv(\"Seattle_Hotels.csv\", header=True, inferSchema=True)\n",
    "# 数据探索\n",
    "df.show(20)\n",
    "print('数据集中的酒店个数：', df.count())\n",
    "\n",
    "# 将desc进行分词\n",
    "tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"desc_words\")\n",
    "df = tokenizer.transform(df)\n",
    "df.show()\n",
    "\n",
    "df.select('desc_words').show()\n",
    "#print('数据集中的酒店个数：', df.length)\n",
    "\n",
    "def print_description(index):\n",
    "    df.where('id='+str(index)).show()\n",
    "print('第10个酒店的描述：')\n",
    "print_description(10)\n",
    "\n",
    "# 停用词\n",
    "add_stopwords = ['the', 'of', 'in', 'a', 'an', 'at', 'as', 'on', 'for', 'it', 'we', 'you', 'want', 'up', 'to', 'if', 'are', 'is', 'and', 'our', 'with', 'from', '-', 'your', 'so']\n",
    "stopwords_remover  = StopWordsRemover(inputCol='desc_words', outputCol='desc_words_filtered').setStopWords(add_stopwords) #inputCol和outputCol指定输入列和输出列，.setStopWords设定停用词表\n",
    "df = stopwords_remover.transform(df)\n",
    "\n",
    "# 计算每篇文档的TF-IDF\n",
    "hashingTF =HashingTF(inputCol='desc_words_filtered', outputCol=\"desc_words_tf\") #hashing是指放在内存里\n",
    "tf = hashingTF.transform(df).cache()\n",
    "idf = IDF(inputCol='desc_words_tf', outputCol=\"desc_words_tfidf\").fit(tf)\n",
    "tfidf = idf.transform(tf).cache()\n",
    "print('\\n 每个酒店的TFIDF')\n",
    "tfidf.select('desc_words_tfidf').show(truncate=False)\n",
    "\n",
    "# 数据规范化\n",
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"desc_words_tfidf\", outputCol=\"norm\")\n",
    "tfidf = normalizer.transform(tfidf)\n",
    "tfidf.select(\"id\", \"norm\").show()\n",
    "\n",
    "import pyspark.sql.functions as psf \n",
    "from pyspark.sql.types import DoubleType\n",
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "#tfidf = tfidf.alias(\"a1\").join(tfidf.alias(\"a2\"), psf.col(\"a1.id\") < psf.col(\"a2.id\")).withColumn('similarity', dot_udf(\"a1.norm\", \"a2.norm\"))\n",
    "#tfidf.show()\n",
    "\n",
    "tfidf = tfidf.alias(\"a1\").join(tfidf.alias(\"a2\"), psf.col(\"a1.id\") < psf.col(\"a2.id\"))\\\n",
    "        .select(\n",
    "            psf.col(\"a1.name\"),\n",
    "            psf.col(\"a1.id\").alias(\"id1\"), \n",
    "            psf.col(\"a2.id\").alias(\"id2\"), \n",
    "            dot_udf(\"a1.norm\", \"a2.norm\").alias(\"similarity\"))\\\n",
    "        .sort(\"id1\", \"id2\")\n",
    "\n",
    "tfidf.show(100)\n",
    "\n",
    "# 基于相似度和指定的酒店name，推荐TOP10酒店\n",
    "def recommendations(name):\n",
    "    temp = tfidf.where('name=\"'+name+'\"').sort('similarity', ascending=False).limit(10)\n",
    "    return temp.select('id2', 'similarity')\n",
    "\n",
    "rec = recommendations('Hilton Seattle Airport & Conference Center')\n",
    "rec.show()\n",
    "rec = recommendations('The Bacon Mansion Bed and Breakfast')\n",
    "rec.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
