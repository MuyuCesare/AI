{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "\n",
    "#数据加载\n",
    "news=pd.read_csv('sqlResult.csv', encoding='gb18030')\n",
    "print(news.shape)\n",
    "print(news.head())\n",
    "\n",
    "news[news.content.isna()].head() #查看content列有没有缺失值\n",
    "news=news.dropna(subset=['content'])\n",
    "print(news.shape)\n",
    "\n",
    "#加载停用词\n",
    "with open('chinese_stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "\tstopwords = [i[:-1] for i in file.readlines()]\n",
    "\t\n",
    "#分词\n",
    "def split_text(text):\n",
    "\ttext=text.replace(' ', '').replace('\\n', '')\n",
    "\ttext2=jieba.cut(text)\n",
    "\tresult=' '.join([w for w in text2 if w not in stopwords])\n",
    "\treturn result\n",
    "\n",
    "corpus=list(map(split_text, [str(i) for i in news.content]))\n",
    "corpus\n",
    "\n",
    "#计算corpus的TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "countvectorizer=CountVectorizer(encoding='gb18030', min_df=0.015)\n",
    "tfidftransformer=TfidfTransformer()\n",
    "countvector=countvectorizer.fit_transform(corpus)\n",
    "tfidf=tfidftransformer.fit_transform(countvector)\n",
    "print(tfidf.shape)\n",
    "\n",
    "#标记是否为自己的新闻\n",
    "label=list(map(lambda source: 1 if '新华社' in str(source) else 0, news.source))\n",
    "label\n",
    "\n",
    "#数据集切分\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(tfidf.toarray(), label, test_size=0.3)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print('准确率：', accuracy_score(y_test, y_predict))\n",
    "print('精确率：', precision_score(y_test, y_predict))\n",
    "print('召回率：', recall_score(y_test, y_predict))\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model=BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print('准确率：', accuracy_score(y_test, y_predict))\n",
    "print('精确率：', precision_score(y_test, y_predict))\n",
    "print('召回率：', recall_score(y_test, y_predict))\n",
    "\n",
    "#使用模型进行风格预测\n",
    "prediction=model.predict(tfidf.toarray())\n",
    "labels=np.array(label)\n",
    "# compare_news_index有两列，prediction为预测风格，labels为真实结果\n",
    "compare_news_index=pd.DataFrame({'prediction': prediction, 'labels': labels})\n",
    "copy_news_index=compare_news_index[(compare_news_index['prediction']==1)&(compare_news_index['labels']==0)].index\n",
    "\n",
    "#实际为新华社的新闻\n",
    "xinhuashe_news_index=compare_news_index[(compare_news_index['labels']==1)].index\n",
    "print('可能为copy的新闻条数：', len(copy_news_index))\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "normalizer = Normalizer()\n",
    "scaled_array=normalizer.fit_transform(tfidf.toarray())\n",
    "\n",
    "#使用Kmeans进行全量文档进行聚类\n",
    "kmeans=KMeans(n_clusters=25)\n",
    "k_labels=kmeans.fit_predict(scaled_array)\n",
    "print(k_labels.shape)\n",
    "\n",
    "#创建id_class，ID是1-87054，class是1-25\n",
    "id_class={index:class_ for index, class_ in enumerate(k_labels)}\n",
    "from collections import defaultdict\n",
    "class_id=defaultdict(set)\n",
    "for index, class_ in id_class.items():\n",
    "\t#只统计新华社发布的class_id\n",
    "\tif index in xinhuashe_news_index.tolist():\n",
    "\t\tclass_id[class_].add(index)\n",
    "\n",
    "#查找相似的文章\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_similar_text(cpindex, top=10):\n",
    "\t#计算指定文章与其所有同一聚类文章的余弦相似度\n",
    "\tdist_dict={i:cosine_similarity(tfidf[cpindex], tfidf[i]) for i in class_id[id_class[cpindex]]}\n",
    "\t#从大到小进行排序\n",
    "\treturn sorted(dist_dict.items(), key=lambda x:x[1][0], reverse=True)[:top]\n",
    "\n",
    "cpindex=3352\n",
    "print('是否在新华社', cpindex in xinhuashe_news_index)\n",
    "print('是否在copy_news', cpindex in copy_news_index)\n",
    "\n",
    "similar_list=find_similar_text(cpindex)\n",
    "print(similar_list)\n",
    "\n",
    "print('怀疑抄袭：\\n', news.iloc[cpindex].content)\n",
    "#找一篇相似的原文\n",
    "similar2=similar_list[0][0]\n",
    "print('相似的原文：\\n', news.iloc[similar2].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
