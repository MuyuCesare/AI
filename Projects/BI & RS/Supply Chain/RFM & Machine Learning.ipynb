{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#数据加载\n",
    "dataset=pd.read_csv('./SupplyChain.csv', encoding='unicode_escape') #如果utf-8报错，则加上encoding='unicode_escape'忽略编码问题\n",
    "dataset.shape\n",
    "temp=dataset.isnull().sum()\n",
    "temp[temp>0]\n",
    "\n",
    "#供应链数据探索\n",
    "dataset[['Customer Fname', 'Customer Lname']]\n",
    "#将firstname与lastname进行合并\n",
    "dataset['Customer Full Name']=dataset['Customer Fname']+dataset['Customer Lname']\n",
    "dataset[['Customer Full Name', 'Customer Fname', 'Customer Lname']]\n",
    "\n",
    "dataset['Customer Zipcode'].value_counts()\n",
    "dataset['Customer Zipcode'].isnull().sum()\n",
    "#用0进行填充\n",
    "dataset['Customer Zipcode']=dataset['Customer Zipcode'].fillna(0)\n",
    "dataset['Customer Zipcode'].isnull().sum()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#特征字段之间相关性，高相关性的特征取一个就好\n",
    "data=dataset\n",
    "data.corr() #创建相关矩阵\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data.corr(),  annot=True, cmap='collwarm') #annot=True则在图中标记相关性具体数值\n",
    "\n",
    "#按照不同的Market、Order Region看sales\n",
    "#基于Market\n",
    "dataset['Market'].value_counts()\n",
    "market=data.groupby('Market')\n",
    "market['Sales per customer'].sum().sort_values(ascending=False).plot.bar(figsize=(12, 6), title='Sales in different markets')\n",
    "#基于Order Region\n",
    "region=data.groupby('Order Region')\n",
    "region['Sales per customer'].sum().sort_values(ascending=False).plot.bar(figsize=(12, 6), title='Sales in different regions')\n",
    "#按照不同的Category Name\n",
    "cat=data.groupby('Category Name')\n",
    "cat['Sales per customer'].sum().sort_values(ascending=False).plot.bar(figsize=(12, 6), title='Salesin different categories')\n",
    "cat['Sales per customer'].mean().sort_values(ascending=False).plot.bar(figsize=(12, 6), title='Salesin different categories')\n",
    "#按照不同的时间维度趋势\n",
    "data['order date (DateOrders)'].describe() #时间是object类型\n",
    "temp=pd.DatetimeIndex(data['order date (DateOrders)']) #将时间转换为DatetimeIndex对象\n",
    "#order date (DateOrders)字段中的year, month, weekday, hour, month_year\n",
    "data['order_year'] = temp.year\n",
    "data['order_month'] = temp.month\n",
    "data['order_week_day'] = temp.weekday\n",
    "data['order_hour'] = temp.hour\n",
    "data['order_month_year'] = temp.to_period('M') #.to_period('M')表示到month为止，即展示年-月，也可以为'H'、'D'\n",
    "data[['order_year', 'order_month', 'order_week_day', 'order_hour', 'order_month_year']]\n",
    "data['order_week_day'].min()\n",
    "data['order_week_day'].max()\n",
    "#对销售额进行探索，按照不同时间维度：年、星期、小时、月\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.subplot(4, 2, 1)\n",
    "df_year=data.groupby('order_year')\n",
    "df_year['Sales'].mean().plot(figsize=(12, 12), title='Mean Sales in years')\n",
    "plt.subplot(4, 2, 2)\n",
    "df_day=data.groupby('order_week_day')\n",
    "df_day['Sales'].mean().plot(figsize=(12, 12), title='Mean Sales in week days')\n",
    "plt.subplot(4, 2, 3)\n",
    "df_hour=data.groupby('order_hour')\n",
    "df_hour['Sales'].mean().plot(figsize=(12, 12), title='Mean Sales in hours')\n",
    "plt.subplot(4, 2, 4)\n",
    "df_month=data.groupby('order_month')\n",
    "df_month['Sales'].mean().plot(figsize=(12, 12), title='Mean Sales in months')\n",
    "\n",
    "#Product Price与Sales per customer相关性如何\n",
    "data.plot(x='Product Price', y='Sales per customer', kind='scatter') #绘制散点图\n",
    "plt.title('Relationship between Product Price and Sales per customer')\n",
    "plt.xlabel('Product Price')\n",
    "plt.ylabel('Sales per customer')\n",
    "\n",
    "#对用户进行分层运营\n",
    "#时间类型转换\n",
    "data['order date (DateOrders)']=pd.to_datetime(data['order date (DateOrders)'])\n",
    "#统计最后一笔订单时间\n",
    "data['order date (DateOrders)'].max()\n",
    "\n",
    "#假设现在是2018-2-1\n",
    "import datetime\n",
    "present = datetime.datetime(2018, 2, 1)\n",
    "\n",
    "#计算每个用户的RFM指标\n",
    "#按照Order Customer Id进行聚合\n",
    "customer_seg=data.groupby('Order Customer Id').agg({'order date (DateOrders)': lambda x:(present-x.max()).days, 'Order Id': lambda x: len(x), 'Sales': lambda x: x.sum()})\n",
    "\n",
    "#将RFM数据划分为4个尺度\n",
    "quantiles=customer_seg.quantile(q=[0.25, 0.5, 0.75])\n",
    "quantiles=quantiles.to_dict()\n",
    "\n",
    "#将字段名称改为R_Value, F_Value, M_Value\n",
    "customer_seg.rename(columns={'order date (DateOrders)': 'R_Value', 'Order Id': 'F_Value', 'Sales': 'M_Value'}, inplace=True)\n",
    "\n",
    "#将Value转换为Score\n",
    "#Recency，越小越好\n",
    "def R_Score(a, b, c):\n",
    "    if a <= c[b][0.25]:\n",
    "        return 4\n",
    "    if a <= c[b][0.50]:\n",
    "        return 3\n",
    "    if a <= c[b][0.75]:\n",
    "        return 2\n",
    "    return 1\n",
    "#Frequency, Money，越大越好\n",
    "def FM_Score(a, b, c):\n",
    "    if a <= c[b][0.25]:\n",
    "        return 1\n",
    "    if a <= c[b][0.50]:\n",
    "        return 2\n",
    "    if a <= c[b][0.75]:\n",
    "        return 3\n",
    "    return 4\n",
    "\n",
    "customer_seg['R_Score']=customer_seg['R_Value'].apply(R_Score, args=('R_Value', quantiles))\n",
    "customer_seg['F_Score']=customer_seg['F_Value'].apply(R_Score, args=('F_Value', quantiles))\n",
    "customer_seg['M_Score']=customer_seg['M_Value'].apply(R_Score, args=('M_Value', quantiles))\n",
    "\n",
    "#计算RFM用户分层\n",
    "def RFM_User(df):\n",
    "    if df['M_Score'] > 2 and df['F_Score'] > 2 and df['R_Score'] >2:\n",
    "        return '重要价值用户'\n",
    "    if df['M_Score'] > 2 and df['F_Score'] <= 2 and df['R_Score'] >2:\n",
    "        return '重要发展用户'\n",
    "    if df['M_Score'] > 2 and df['F_Score'] > 2 and df['R_Score'] <=2:\n",
    "        return '重要保持用户'\n",
    "    if df['M_Score'] > 2 and df['F_Score'] <= 2 and df['R_Score'] <=2:\n",
    "        return '重要挽留用户'\n",
    "    if df['M_Score'] <= 2 and df['F_Score'] > 2 and df['R_Score'] >2:\n",
    "        return '一般价值用户'\n",
    "    if df['M_Score'] <= 2 and df['F_Score'] <= 2 and df['R_Score'] >2:\n",
    "        return '一般发展用户'\n",
    "    if df['M_Score'] <= 2 and df['F_Score'] > 2 and df['R_Score'] <=2:\n",
    "        return '一般保持用户'\n",
    "    if df['M_Score'] <= 2 and df['F_Score'] <= 2 and df['R_Score'] <=2:\n",
    "        return '一般挽留用户'\n",
    "\n",
    "customer_seg['Customer_Segmentation']=customer_seg.apply(RFM_User, axis=1)\n",
    "\n",
    "#显示不同地区的支付类型情况\n",
    "data['Type'].value_count()\n",
    "pay_type1=data[data['Type']=='DEBIT']\n",
    "pay_type2=data[data['Type']=='TRANSFER']\n",
    "pay_type3=data[data['Type']=='PAYMENT']\n",
    "pay_type4=data[data['Type']=='CASH']\n",
    "\n",
    "#获取4种支付方式中，不同地区的特点\n",
    "count1=pay_type1['Order Region'].value_counts() #DEBIT\n",
    "count2=pay_type2['Order Region'].value_counts() #TRANSFER\n",
    "count3=pay_type3['Order Region'].value_counts() #PAYMENT\n",
    "count4=pay_type4['Order Region'].value_counts() #CASH\n",
    "\n",
    "#获取地区region的个数\n",
    "region_num=len(count1)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "index=np.arange(region_num)\n",
    "#每种类型的显示间隔\n",
    "bar_width=0.2\n",
    "type1=plt.bar(index, count1, bar_width, color='b', label='DEBIT')\n",
    "type2=plt.bar(index+bar_width, count2, bar_width, color='r', label='TRANSFER') #+bar_width能够做出多bar对比展示的效果\n",
    "type3=plt.bar(index+bar_width*2, count3, bar_width, color='g', label='PAYMENT')\n",
    "type4=plt.bar(index+bar_width*3, count4, bar_width, color='y', label='CASH')\n",
    "plt.xlabel('Order Region')\n",
    "plt.ylabel('Number of payments')\n",
    "plt.title('Type of payments in all regions')\n",
    "plt.legend()\n",
    "#显示刻度\n",
    "names=data['Order Region'].value_counts().keys()\n",
    "plt.xticks(index+bar_width, names, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "分析结论\n",
    "DEBIT支付是所有地区中使用次数最多的方式\n",
    "CASH支付是所有地区中使用次数最少的方式\n",
    "'''\n",
    "\n",
    "#对于欺诈订单和迟交货订单进行预测\n",
    "#对负收益产品进行探索\n",
    "loss=data[data['Benefit per order'] < 0]\n",
    "#显示top10的负收益产品并用bar可视化\n",
    "loss['Category Name'].value_counts().nlargest(10).plot.bar(figsize=(20, 8), title='Products with most loss')\n",
    "\n",
    "#显示Top10的负收益地区\n",
    "loss['Order Region'].value_counts().nlargest(10).plot.bar(figsize=(20, 8), title='Regions with most loss')\n",
    "\n",
    "#所有负收益产品带来的损失\n",
    "print('总损失',  loss['Benefit per order'].sum())\n",
    "\n",
    "#负收益，可能是欺诈交易，来自于哪种支付方式\n",
    "data[data['Order Status']=='SUSPECTED_FRAUD']['Type'].value_counts() #发现只有TRANSFER\n",
    "\n",
    "#显示不同地区的欺诈交易情况\n",
    "high_fraud=data[data['Order Status']=='SUSPECTED_FRAUD']\n",
    "high_fraud['Order Region'].value_counts().plot.bar(figsize=(20, 8))\n",
    "plt.title('Regions with Highest Fraud')\n",
    "plt.ylabel('Fraud Number')\n",
    "plt.show()\n",
    "\n",
    "#Western Europe地区欺诈交易最多，将一个bar分成2个部分(堆积条形图)\n",
    "high_fraud_total=data[data['Order Status']=='SUSPECTED_FRAUD']\n",
    "high_fraud_we=data[(data['Order Status']=='SUSPECTED_FRAUD']) & (data['Order Status']=='Western Europe')]\n",
    "#找出风险最高的10个Category\n",
    "fraud1=high_fraud_total['Category Name'].value_counts().nlargest(10).plot.bar(figsize=(20, 8), title='Fraud Category', color='orange')\n",
    "fraud2=high_fraud_we['Category Name'].value_counts().nlargest(10).plot.bar(figsize=(20, 8), title='Fraud Category in Western Europe', color='green')\n",
    "plt.title('Top10 Categories with highest fraud')\n",
    "plt.xlabel('Products')\n",
    "plt.show()\n",
    "\n",
    "#筛选出Top10 Customer(风险)\n",
    "cus=data[data['Order Status']=='SUSPECTED_FRAUD']\n",
    "cus['Customer Full Name'].value_counts().nlargest(10).plot.bar(figsize=(20, 8), title='Top10 Highest Fraud Customers') #发现最高Customer Name是MarySmith\n",
    "\n",
    "#找到MarySmith的交易金额和疑似欺诈的交易金额\n",
    "print(data[data['Customer Full Name']=='MarySmith']['Sales'].sum())\n",
    "print(data[(data['Customer Full Name']=='MarySmith') & (data['Order Status']=='SUSPECTED_FRAUD')]['Sales'].sum())\n",
    "\n",
    "import pickle\n",
    "with open('data.pkl', 'wb') as file: #将数据保存为pickle，读取比csv快\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "import pickle\n",
    "with open('data.pkl', 'rb') as file: #读取pickle\n",
    "    train_data=pickle.load(file)\n",
    "\n",
    "import numpy as np\n",
    "train_data['fraud']=np.where(train_data['Order Status']=='SUSPECTED_FRAUD', 1, 0)\n",
    "train_data['fraud'].sum() #总计有多少笔欺诈行为\n",
    "train_data['late_delivery']=np.where(train_data['Delivery Status']=='Late delivery', 1, 0)\n",
    "train_data.info()\n",
    "categorical_cols=train_data.select_dtypes(include='object').columns\n",
    "for column in train_data.columns: #看哪些字段只有1个取值或所有取值都不同\n",
    "    if (len(train_data[column].value_counts())<2) or (len(train_data[column].value_counts())=len(train_data)):\n",
    "        print(column)\n",
    "train_data.drop(['Customer Email', 'Customer Password', 'Product Description', 'Product Status', 'Product Image', 'Customer Lname', 'Customer Fname'], axis=1, inplace=True)\n",
    "train_data.drop(['Order Customer Id', 'Order Item Cardprod Id', 'Order Item Id', 'Sales per customer', 'Order Item Total', 'Order Profit Per Order', 'Product Card Id', 'Product Category Id', 'Product Price'], axis=1, inplace=True) #去掉相关性热力图中相关性高的字段\n",
    "train_data.drop(['Order Status', 'Delivery Status', 'Late_delivery_risk'], axis=1, inplace=True) #去掉会引起标签泄露的字段(预测时把标签放进了特征会导致预测全满分)\n",
    "\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train_data.drop(['Order Zipcode', 'shipping data (DateOrders)', 'Latitude', 'Longitude', 'Customer Street', 'order date (DateOrders)', 'order_month_year'], axis=1, inplace=True) #去掉空值过多的字段、时间字段如果不diff也可以去掉、经纬度如果觉得没啥用也可以考虑去掉，训练集测试集分布不一致的字段可以考虑去掉\n",
    "train_data.info()\n",
    "train_data=train_data.dropna(subset=['Customer Full Name']) #去掉该字段中的为空的行\n",
    "\n",
    "#对类别变量LabelEncoder\n",
    "categorical_cols=train_data.select_dtypes(include='object').columns\n",
    "from sklearn.preprocessing import LabelEncoder #LabelEncoder不允许有空值\n",
    "le=LabelEncoder()\n",
    "for cat in categorical_cols:\n",
    "    train_data[cat]=le.fit_transform(train_data[cat])\n",
    "train_data[categorical_cols]\n",
    "\n",
    "#对数值类型变量\n",
    "numerical_columns=train_data.columns.tolist()\n",
    "for x in categorical_cols.tolist():\n",
    "    numerical_columns.remove(x)\n",
    "\n",
    "x_fraud=train_data.loc[:, train_data.columns != 'fraud']\n",
    "y_fraud=train_data['fraud']\n",
    "x_late=train_data.loc[:, train_data.columns != 'late_delivery']\n",
    "y_late=train_data['late_delivery']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#数据集切分\n",
    "x_fraud_train, x_fraud_test, y_fraud_train, y_fraud_test=train_test_split(x_fraud, y_fraud, test_size=0.2)\n",
    "x_late_train, x_late_test, y_late_train, y_late_test=train_test_split(x_late, y_late, test_size=0.2)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#数据规范化(分类函数如果用到了关于距离的定义则需要规范化，决策树不需要规范化(根据信息增益ID3，信息增益率C4.5和基尼系数而不是按距离分类))\n",
    "sc=StandardScaler()\n",
    "x_fraud_train=sc.fit_transform(x_fraud_train)\n",
    "x_fraud_test=sc.transform(x_fraud_test)\n",
    "x_late_train=sc.fit_transform(x_late_train)\n",
    "x_late_test=sc.transform(x_late_test)\n",
    "\n",
    "accuracy_list={}\n",
    "recall_list={}\n",
    "auc_list={}\n",
    "f1_list={}\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix, f1_score\n",
    "def model_stats(model, x_train, x_test, y_train, y_test, name='Fraud'):\n",
    "    model=model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_pred, y_test)\n",
    "    recall=recall_score(y_pred, y_test)\n",
    "    auc=roc_auc_score(y_pred, y_test)\n",
    "    f1=f1_score(y_pred, y_test)\n",
    "\n",
    "    accuracy_list[name, model]=accuracy\n",
    "    recall_list[name, model]=recall\n",
    "    auc_list[name, model]=auc\n",
    "    f1_list[name, model]=f1\n",
    "\n",
    "    confusion=confusion_matrix(y_pred, y_test)\n",
    "    print('Model Used: ', model)\n",
    "    print('{} Accuracy: {}%'.format(name, accuracy*100))\n",
    "    print('{} Recall: {}%'.format(name, recall*100))\n",
    "    print('{} AUC: {}%'.format(name, auc*100))\n",
    "    print('{} F1 Score: {}%'.format(name, f1*100))\n",
    "    print('{} Confusion Matrix: \\n{}'.format(name, confusion))\n",
    "    return accuracy, recall, f1\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#逻辑回归模型\n",
    "model_fraud=LogisticRegression()\n",
    "model_late=LogisticRegression()\n",
    "model_stats(model_fraud, x_fraud_train, x_fraud_test, y_fraud_train, y_fraud_test, 'Fraud')\n",
    "model_stats(model_late, x_late_train, x_late_test, y_late_train, y_late_test, 'Late Delivery')\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "#高斯朴素贝叶斯\n",
    "model_fraud=GaussianNB()\n",
    "model_late=GaussianNB()\n",
    "#贝努利朴素贝叶斯\n",
    "model_fraud=BernoulliNB()\n",
    "model_late=BernoulliNB()\n",
    "#SVM\n",
    "model_fraud=svm.LinearSVC()\n",
    "model_late=svm.LinearSVC()\n",
    "#决策树模型和feature importance可视化\n",
    "model_fraud=DecisionTreeClassifier()\n",
    "model_late=DecisionTreeClassifier()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model_fraud.feature_importances_ #根据决策树模型，得到feature importance\n",
    "important_col=model_fraud.feature_importances_.argsort() #得到feature importance的对应列号\n",
    "print(important_col)\n",
    "feat_importance=pd.DataFrame({'features': x_fraud.columns[important_col], 'importance': model_fraud.feature_importances_[important_col]})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "feat_importance.sort_values(by='importance', ascending=False)\n",
    "sns.catplot(x='features', y='importance', data=feat_importance, kind='bar', height=5, aspect=2)\n",
    "plt.xticks(rotation=90)\n",
    "#KNN模型\n",
    "model_fraud=KNeighborsClassifier(n_neighbors=1)\n",
    "model_late=KNeighborsClassifier()\n",
    "#LDA模型\n",
    "model_fraud=LinearDiscriminantAnalysis()\n",
    "model_late=LinearDiscriminantAnalysis()\n",
    "#随机森林模型\n",
    "model_fraud=RandomForestClassifier()\n",
    "model_late=RandomForestClassifier()\n",
    "#XGBoost分类\n",
    "model_fraud=xgb.XGBClassifier()\n",
    "model_late=xgb.XGBClassifier()\n",
    "\n",
    "#模型评估\n",
    "model_stats(model_fraud, x_fraud_train, x_fraud_test, y_fraud_train, y_fraud_test, 'Fraud')\n",
    "model_stats(model_late, x_late_train, x_late_test, y_late_train, y_late_test, 'Late Delivery')\n",
    "\n",
    "#神经网络进行分类\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "keras.layers.BatchNormalization()\n",
    "classifier=Sequential()\n",
    "#第1层隐藏层\n",
    "classifier.add(Dense(1024, activation='relu', kernel_initializer='random_normal', input_dim=x_fraud_train.shape[1]))\n",
    "#第2层隐藏层\n",
    "classifier.add(Dense(512, activation='relu', kernel_initializer='random_normal'))\n",
    "#第3层隐藏层\n",
    "classifier.add(Dense(256, activation='relu', kernel_initializer='random_normal'))\n",
    "#第4层隐藏层\n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal'))\n",
    "#第5层隐藏层\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "#第6层隐藏层\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#第7层隐藏层\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#第8层隐藏层\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "#第9层隐藏层\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "#第10层隐藏层\n",
    "classifier.add(Dense(2, activation='relu', kernel_initializer='random_normal'))\n",
    "#输出层\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#定义优化器、损失函数\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#训练\n",
    "classifier.fit(x_fraud_train, y_fraud_train, batch_size=512, epochs=10)\n",
    "#评估\n",
    "train_evaluate=classifier.evaluate(x_fraud_train, y_fraud_train)\n",
    "test_evaluate=classifier.evaluate(x_fraud_test, y_fraud_test)\n",
    "print('训练集准确率：', train_evaluate)\n",
    "print('测试集准确率：', test_evaluate)\n",
    "\n",
    "#模型融合\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#硬投票\n",
    "ensemble_model=VotingClassifier(estimators=[('LR', model_fraud_lr), ('DT', model_fraud_dt), ('SVC', model_fraud_svc)], voting='hard')\n",
    "for model, label in zip([model_fraud_lr, model_fraud_dt, model_fraud_svc, ensemble_model], ['LR', 'DT', 'SVC', 'Voting']):\n",
    "    #scores=cross_val_score(model, x_fraud, y_fraud, cv=5, scoring='accuracy')\n",
    "    #scores=cross_val_score(model, x_fraud, y_fraud, cv=5, scoring='auc_roc')\n",
    "    scores=cross_val_score(model, x_fraud, y_fraud, cv=5, scoring='f1')\n",
    "    print('F1: {:0.2f} (+/- {:0.2f}) [{}]'.format(scores.mean(), scores.std(), label))\n",
    "\n",
    "#对于销售额进行预测，即Sales字段\n",
    "#对于订货数量进行预测，即Order Item Quantity\n",
    "x_sales=train_data.loc[:, train_data.columns !='Sales']\n",
    "y_sales=train_data['Sales']\n",
    "\n",
    "x_quantity=train_data.loc[:, train_data.columns !='Order Item Quantity']\n",
    "y_quantity=train_data['Order Item Quantity']\n",
    "\n",
    "#数据集切分\n",
    "x_sales_train, x_sales_test, y_sales_train, y_sales_test=train_test_split(x_sales, y_sales, test_size=0.2)\n",
    "x_quantity_train, x_quantity_test, y_quantity_train, y_quantity_test=train_test_split(x_quantity, y_quantity, test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#回归模型，采用MSE, MAE, RMSE指标\n",
    "def regression_model_stats(model, x_train, x_test, y_train, y_test, model_name='Sales'):\n",
    "    model=model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    print('Model Used:', model)\n",
    "    mae=mean_absolute_error(y_test, y_pred)\n",
    "    mse=mean_squared_error(y_test, y_pred)\n",
    "    print('{} MAE {}'.format(model_name, mae))\n",
    "    print('{} MSE {}'.format(model_name, mse))\n",
    "    return mae, mse\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "import lightgbm as lgb\n",
    "#Linear Regression\n",
    "model_sales=LinearRegression()\n",
    "model_quantitiy=LinearRegression()\n",
    "#Lasso Regression\n",
    "model_sales=Lasso()\n",
    "model_quantitiy=Lasso()\n",
    "#Ridge Regression\n",
    "model_sales=Ridge()\n",
    "model_quantitiy=Ridge()\n",
    "#Decision Tree Regressor\n",
    "model_sales=DecisionTreeRegressor()\n",
    "model_quantitiy=DecisionTreeRegressor()\n",
    "#XGBoost回归\n",
    "model_sales=xgb.XGBRegressor()\n",
    "model_quantitiy=xgb.XGBRegressor()\n",
    "#LightGBM回归\n",
    "model_sales=lgb.LGBMRegressor()\n",
    "model_quantitiy=lgb.LGBMRegressor()\n",
    "#随机森林\n",
    "model_sales=RandomForestRegressor()\n",
    "model_quantitiy=RandomForestRegressor()\n",
    "\n",
    "#模型评估\n",
    "regression_model_stats(model_sales, x_sales_train, x_sales_test, y_sales_train, y_sales_test, model_name='Sales')\n",
    "regression_model_stats(model_quantitiy_sales, x_quantitiy_train, x_quantitiy_test, y_quantitiy_train, y_quantitiy_test, model_name='Quantity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
