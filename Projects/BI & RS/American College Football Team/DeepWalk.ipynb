{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用DeepWalk\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 数据加载，构造图\n",
    "G = nx.read_gml('football.gml')\n",
    "#球队总数\n",
    "print(len(G)) \n",
    "#都有哪些球队\n",
    "#print(G.nodes()) \n",
    "#都有哪些比赛\n",
    "#print(G.edges()) \n",
    "\n",
    "\"\"\" \n",
    "随机游走\n",
    "input: 将节点和被遍历的路径的长度作为输入\n",
    "output: 返回遍历节点的顺序:\n",
    "\"\"\"\n",
    "def get_randomwalk(node, path_length):\n",
    "    random_walk = [node]\n",
    "    for i in range(path_length-1):\n",
    "        temp = list(G.neighbors(node)) #找到节点的邻居\n",
    "        temp = list(set(temp) - set(random_walk)) #去掉已经走过的点\n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "        random_node = random.choice(temp) #从列表中随机选择一个\n",
    "        random_walk.append(random_node)\n",
    "        node = random_node        \n",
    "    return random_walk\n",
    "\n",
    "#print(get_randomwalk('EastCarolina', 10))\n",
    "\n",
    "# 从图获取所有节点的列表\n",
    "all_nodes = list(G.nodes())\n",
    "# 捕获数据集中所有节点的随机游走序列\n",
    "random_walks = []\n",
    "for n in tqdm(all_nodes): # 每个节点游走5次，每次最长距离为10\n",
    "    for i in range(5):\n",
    "        random_walks.append(get_randomwalk(n,10))\n",
    "\n",
    "# 输出随机游走序列，及序列个数\n",
    "#print(random_walks)\n",
    "#print(len(random_walks))\n",
    "\n",
    "# 使用skip-gram，提取模型学习到的权重\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 训练skip-gram(word2vec)模型\n",
    "model = Word2Vec(window = 4, sg = 1, hs = 0,\n",
    "                 negative = 10, # 负采样\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "# 从random_walks的所有句子创建词汇表\n",
    "model.build_vocab(random_walks, progress_per=2)\n",
    "model.train(random_walks, total_examples = model.corpus_count, epochs=20, report_delay=1)\n",
    "print(model)\n",
    "# 输出和EastCarolina相似的球队\n",
    "print(model.similar_by_word('EastCarolina'))\n",
    "\n",
    "# 在二维空间中绘制所选节点的向量\n",
    "def plot_nodes(word_list):\n",
    "    X = model[word_list] # 提取节点的词向量，每个节点的embedding为100维\n",
    "    #print(type(X))\n",
    "    # 将100维向量减少到2维\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(X) \n",
    "    #print(result)\n",
    "    # 绘制节点向量\n",
    "    plt.figure(figsize=(12,9))\n",
    "    # 创建一个散点图的投影\n",
    "    plt.scatter(result[:, 0], result[:, 1])\n",
    "    for i, word in enumerate(word_list): #给每个点备注上文字\n",
    "        plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "    plt.show()\n",
    "# 将所有的球队embedding进行绘制\n",
    "plot_nodes(model.wv.vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
